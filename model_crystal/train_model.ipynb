{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557\n",
      "Epoch 1/50\n",
      "369/369 [==============================] - 226s 597ms/step - loss: 2.6455 - accuracy: 0.1129 - val_loss: 2.4237 - val_accuracy: 0.1786\n",
      "Epoch 2/50\n",
      "369/369 [==============================] - 222s 601ms/step - loss: 2.2764 - accuracy: 0.2165 - val_loss: 2.4169 - val_accuracy: 0.1847\n",
      "Epoch 3/50\n",
      "369/369 [==============================] - 223s 606ms/step - loss: 1.9558 - accuracy: 0.3232 - val_loss: 2.4452 - val_accuracy: 0.2206\n",
      "Epoch 4/50\n",
      "369/369 [==============================] - 222s 602ms/step - loss: 1.5991 - accuracy: 0.4580 - val_loss: 2.5579 - val_accuracy: 0.2115\n",
      "Epoch 5/50\n",
      "369/369 [==============================] - 266s 722ms/step - loss: 1.2264 - accuracy: 0.6023 - val_loss: 2.7561 - val_accuracy: 0.1947\n",
      "Epoch 6/50\n",
      "369/369 [==============================] - 251s 680ms/step - loss: 0.8204 - accuracy: 0.7386 - val_loss: 3.1094 - val_accuracy: 0.1756\n",
      "Epoch 7/50\n",
      "369/369 [==============================] - 240s 650ms/step - loss: 0.5558 - accuracy: 0.8314 - val_loss: 3.4395 - val_accuracy: 0.1962\n",
      "Epoch 8/50\n",
      "369/369 [==============================] - 253s 685ms/step - loss: 0.4085 - accuracy: 0.8770 - val_loss: 3.6583 - val_accuracy: 0.1870\n",
      "Epoch 9/50\n",
      "369/369 [==============================] - 238s 645ms/step - loss: 0.3060 - accuracy: 0.9084 - val_loss: 3.9875 - val_accuracy: 0.1756\n",
      "Epoch 10/50\n",
      "369/369 [==============================] - 222s 601ms/step - loss: 0.2344 - accuracy: 0.9320 - val_loss: 4.2227 - val_accuracy: 0.1702\n",
      "Epoch 11/50\n",
      "369/369 [==============================] - 214s 579ms/step - loss: 0.1938 - accuracy: 0.9436 - val_loss: 4.4055 - val_accuracy: 0.1855\n",
      "Epoch 12/50\n",
      "369/369 [==============================] - 215s 583ms/step - loss: 0.1773 - accuracy: 0.9476 - val_loss: 4.6301 - val_accuracy: 0.1779\n",
      "Epoch 13/50\n",
      "369/369 [==============================] - 214s 579ms/step - loss: 0.2166 - accuracy: 0.9373 - val_loss: 4.2045 - val_accuracy: 0.1489\n",
      "Epoch 14/50\n",
      "369/369 [==============================] - 211s 573ms/step - loss: 0.2206 - accuracy: 0.9347 - val_loss: 4.8586 - val_accuracy: 0.1473\n",
      "Epoch 15/50\n",
      "369/369 [==============================] - 212s 574ms/step - loss: 0.1705 - accuracy: 0.9494 - val_loss: 4.9816 - val_accuracy: 0.1489\n",
      "Epoch 16/50\n",
      "369/369 [==============================] - 211s 571ms/step - loss: 0.1250 - accuracy: 0.9624 - val_loss: 5.1833 - val_accuracy: 0.1504\n",
      "Epoch 17/50\n",
      "369/369 [==============================] - 211s 572ms/step - loss: 0.1045 - accuracy: 0.9674 - val_loss: 5.4810 - val_accuracy: 0.1595\n",
      "Epoch 18/50\n",
      "369/369 [==============================] - 212s 573ms/step - loss: 0.1190 - accuracy: 0.9638 - val_loss: 5.4369 - val_accuracy: 0.1580\n",
      "Epoch 19/50\n",
      "369/369 [==============================] - 212s 574ms/step - loss: 0.1453 - accuracy: 0.9559 - val_loss: 5.4305 - val_accuracy: 0.1489\n",
      "Epoch 20/50\n",
      "369/369 [==============================] - 213s 578ms/step - loss: 0.1412 - accuracy: 0.9575 - val_loss: 5.1831 - val_accuracy: 0.1542\n",
      "Epoch 21/50\n",
      "369/369 [==============================] - 215s 584ms/step - loss: 0.1168 - accuracy: 0.9637 - val_loss: 5.4369 - val_accuracy: 0.1588\n",
      "Epoch 22/50\n",
      "369/369 [==============================] - 215s 581ms/step - loss: 0.1249 - accuracy: 0.9616 - val_loss: 5.1514 - val_accuracy: 0.1588\n",
      "Epoch 23/50\n",
      "369/369 [==============================] - 211s 573ms/step - loss: 0.1159 - accuracy: 0.9634 - val_loss: 5.4901 - val_accuracy: 0.1641\n",
      "Epoch 24/50\n",
      "369/369 [==============================] - 215s 582ms/step - loss: 0.1042 - accuracy: 0.9678 - val_loss: 5.5942 - val_accuracy: 0.1588\n",
      "Epoch 25/50\n",
      "369/369 [==============================] - 211s 573ms/step - loss: 0.1037 - accuracy: 0.9672 - val_loss: 5.6723 - val_accuracy: 0.1718\n",
      "Epoch 26/50\n",
      "369/369 [==============================] - 212s 575ms/step - loss: 0.0898 - accuracy: 0.9716 - val_loss: 5.8876 - val_accuracy: 0.1710\n",
      "Epoch 27/50\n",
      "144/369 [==========>...................] - ETA: 6:46 - loss: 0.0883 - accuracy: 0.9720"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     69\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_text, y_train, validation_data\u001b[39m=\u001b[39;49m(X_test_text, y_test),\n\u001b[0;32m     71\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n\u001b[0;32m     73\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[0;32m     74\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mmodel2_with_13000.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fayyo\\.conda\\envs\\keras1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\fayyo\\.conda\\envs\\keras1\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\fayyo\\.conda\\envs\\keras1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\fayyo\\.conda\\envs\\keras1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\fayyo\\.conda\\envs\\keras1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\fayyo\\.conda\\envs\\keras1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\fayyo\\.conda\\envs\\keras1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\fayyo\\.conda\\envs\\keras1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\fayyo\\.conda\\envs\\keras1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('valuable_data_lastone.csv')\n",
    "cols=['position 1', 'position 2', 'field of studies 1','experince 1', 'experince 2', 'field of studies 2',\n",
    "       'degree 1', 'degree 2', 'industry', 'skills', 'influencer', 'country']\n",
    "\n",
    "for col in cols:\n",
    "  data[col] = data[col].fillna(\"Unknown\")\n",
    "# Convert non-string values to strings in the feature columns\n",
    "text_features = data[['position 1', 'position 2', \"experince 1\",\"experince 2\", \n",
    "                      'field of studies 1', 'field of studies 2', \n",
    "                      'degree 1', 'degree 2', 'industry', 'skills',\n",
    "                      'influencer', 'country', 'summary']].copy()\n",
    "\n",
    "# Handle non-string values in each column\n",
    "for column in text_features.columns:\n",
    "    text_features[column] = text_features[column].astype(str)\n",
    "\n",
    "# Combine all text features into a single string column\n",
    "text_data = text_features.apply(lambda x: ' '.join(x), axis=1).tolist()\n",
    "labels = data['characters'].tolist()\n",
    "\n",
    "# Convert labels to integers\n",
    "label_mapping = {label: idx for idx, label in enumerate(set(labels))}\n",
    "y = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "# Update label mapping to start from 0\n",
    "label_mapping = {label: idx for label, idx in label_mapping.items()}\n",
    "num_classes = len(label_mapping)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "sequences = tokenizer.texts_to_sequences(text_data)\n",
    "\n",
    "# Pad sequences to have consistent length\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "print(max_sequence_length)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Convert the data to NumPy arrays\n",
    "X_text = np.array(padded_sequences)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Textual input branch\n",
    "text_input = Input(shape=(max_sequence_length,))\n",
    "embedding_layer = Embedding(vocab_size, 100, input_length=max_sequence_length)(text_input)\n",
    "lstm_layer = LSTM(100)(embedding_layer)\n",
    "output_layer = Dense(num_classes, activation='softmax')(lstm_layer)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=text_input, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_text, y_train, validation_data=(X_test_text, y_test),\n",
    "          epochs=10, batch_size=32)\n",
    "\n",
    "# Save the model\n",
    "model.save('model2_with_13000.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"./last_60k_with_chars.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "characters\n",
       "Cs (Editor)        5810\n",
       "C (Analyst)        4490\n",
       "SC (Stabilizer)    4043\n",
       "Sc (Planner)       3415\n",
       "S (Supporter)      3009\n",
       "Cd (Skeptic)       2885\n",
       "Si (Counselor)     2883\n",
       "Is (Encourager)    2858\n",
       "IS (Harmonizer)    2808\n",
       "I (Motivator)      2424\n",
       "Id (Influencer)    2193\n",
       "CD (Questioner)    1977\n",
       "DI (Initiator)     1752\n",
       "Di (Driver)        1749\n",
       "Dc (Architect)     1689\n",
       "D (Captain)        1516\n",
       "Encourager (Is)    1481\n",
       "Harmonizer (IS)    1467\n",
       "Editor (Cs)        1383\n",
       "Counselor (Si)     1331\n",
       "Analyst (C)        1153\n",
       "Supporter (S)      1130\n",
       "Motivator (I)      1126\n",
       "Planner (Sc)       1120\n",
       "Stabilizer (SC)    1075\n",
       "Influencer (Id)     901\n",
       "Skeptic (Cd)        838\n",
       "Driver (Di)         779\n",
       "Initiator (DI)      746\n",
       "Questioner (CD)     634\n",
       "Captain (D)         622\n",
       "Architect (Dc)      610\n",
       "Driver (Di);          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['characters'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"last_60k_with_chars.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_element(value):\n",
    "    # Example: Multiply each element by 2\n",
    "    a=value.replace(\" \",\"\").replace(\")\",\"\").split(\"(\")\n",
    "    return max(a, key=len)\n",
    "\n",
    "# Use a for loop to iterate through the column and modify elements\n",
    "for index, row in data.iterrows():\n",
    "    data.at[index, 'characters'] = modify_element(row['characters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "characters\n",
       "Editor        7193\n",
       "Analyst       5643\n",
       "Stabilizer    5118\n",
       "Planner       4535\n",
       "Encourager    4339\n",
       "Harmonizer    4275\n",
       "Counselor     4214\n",
       "Supporter     4139\n",
       "Skeptic       3723\n",
       "Motivator     3550\n",
       "Influencer    3094\n",
       "Questioner    2611\n",
       "Driver        2529\n",
       "Initiator     2498\n",
       "Architect     2299\n",
       "Captain       2138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['characters'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24935379644588046\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Analyst       0.31      0.25      0.28      1142\n",
      "   Architect       0.19      0.16      0.17       437\n",
      "     Captain       0.30      0.10      0.15       404\n",
      "   Counselor       0.21      0.29      0.24       816\n",
      "      Driver       0.27      0.27      0.27       539\n",
      "      Editor       0.33      0.54      0.41      1395\n",
      "  Encourager       0.20      0.33      0.25       862\n",
      "  Harmonizer       0.24      0.19      0.21       877\n",
      "  Influencer       0.21      0.22      0.22       636\n",
      "   Initiator       0.24      0.18      0.21       485\n",
      "   Motivator       0.13      0.05      0.07       683\n",
      "     Planner       0.23      0.24      0.23       905\n",
      "  Questioner       0.21      0.08      0.12       547\n",
      "     Skeptic       0.22      0.27      0.24       760\n",
      "  Stabilizer       0.31      0.25      0.27      1048\n",
      "   Supporter       0.18      0.15      0.16       844\n",
      "\n",
      "    accuracy                           0.25     12380\n",
      "   macro avg       0.24      0.22      0.22     12380\n",
      "weighted avg       0.24      0.25      0.24     12380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "X = data[['position 1', 'position 2', 'field of studies 1', 'field of studies 2',\n",
    "          'degree 1', 'degree 2', 'industry', 'skills',  'summary']]\n",
    "y = data['characters']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Preprocess text data using spaCy for tokenization:\n",
    "def tokenize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.text for token in doc])\n",
    "\n",
    "X_train['tokenized_text'] = X_train.apply(lambda row: tokenize_text(\" \".join(row.astype(str))), axis=1)\n",
    "X_test['tokenized_text'] = X_test.apply(lambda row: tokenize_text(\" \".join(row.astype(str))), axis=1)\n",
    "\n",
    "# TF-IDF Vectorization:\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['tokenized_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['tokenized_text'])\n",
    "\n",
    "# Train a classification model (e.g., Multinomial Naive Bayes):\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set:\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance:\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digital Marketing Manager\n",
      "Predicted Character: Cd (Skeptic)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "positions0=[]\n",
    "positions1=[]\n",
    "\n",
    "skills=[]\n",
    "field_of_studies0=[]\n",
    "field_of_studies1=[]\n",
    "degrees0=[]\n",
    "degrees1=[]\n",
    "industries=[]\n",
    "summaries=[]\n",
    "# model_crystal\\datas\\13000_profiles_without_duplicates.csv\n",
    "with open(f'./datas/json_responses_13000/13075.json', 'r') as json_file:\n",
    "    res = json.load(json_file)\n",
    "        \n",
    "try:\n",
    "    skills.append(res['skills'])\n",
    "except:\n",
    "    skills.append(None)\n",
    "try:\n",
    "    position0=res['position_groups'][0]['profile_positions'][0]['title']\n",
    "    print(position0)\n",
    "    positions0.append(position0)\n",
    "except:\n",
    "    positions0.append(None)\n",
    "\n",
    "try:\n",
    "    position1=res['position_groups'][1]['profile_positions'][0]['title']\n",
    "    positions1.append(position1)\n",
    "except:\n",
    "    positions1.append(None)\n",
    "\n",
    "field_of_study0=\"\"\n",
    "try:\n",
    "    field_of_study0=res['education'][0]['field_of_study']\n",
    "    field_of_studies0.append(field_of_study0)\n",
    "except:\n",
    "    field_of_study0=None\n",
    "    field_of_studies0.append(field_of_study0)\n",
    "\n",
    "try:\n",
    "    field_of_study1=res['education'][1]['field_of_study']\n",
    "    field_of_studies1.append(field_of_study1)\n",
    "except:\n",
    "    field_of_study1=None\n",
    "    field_of_studies1.append(field_of_study1)\n",
    "\n",
    "try:\n",
    "    degree_name0=res['education'][0]['degree_name']\n",
    "    degrees0.append(degree_name0)\n",
    "except:\n",
    "    degree_name0=None\n",
    "    degrees0.append(degree_name0)\n",
    "\n",
    "try:\n",
    "    degree_name1=res['education'][1]['degree_name']\n",
    "    degrees1.append(degree_name1)\n",
    "except:\n",
    "    degree_name1=None\n",
    "    degrees1.append(degree_name1)\n",
    "\n",
    "try:\n",
    "    summaries.append(res['summary'])\n",
    "except:\n",
    "    summaries.append(None)\n",
    "try:\n",
    "    industries.append(res['industry'])\n",
    "except:\n",
    "    industries.append(None)\n",
    "\n",
    "user_input = pd.DataFrame({\n",
    "    'position 1': positions0[0],\n",
    "    'position 2': positions1[0],\n",
    "    'field of studies 1': field_of_studies0[0],\n",
    "\n",
    "    'field of studies 2': field_of_studies1[0],\n",
    "    'degree 1':degrees0[0],\n",
    "    'degree 2':degrees1[0],\n",
    "    'industry': industries[0],\n",
    "    'skills': skills[0],\n",
    "})\n",
    "user_input['tokenized_text'] = user_input.apply(lambda row: tokenize_text(\" \".join(row.astype(str))), axis=1)\n",
    "\n",
    "# TF-IDF Vectorization for user input\n",
    "user_input_tfidf = tfidf_vectorizer.transform(user_input['tokenized_text'])\n",
    "\n",
    "# Predict the character for the user input\n",
    "predicted_character = clf.predict(user_input_tfidf)\n",
    "\n",
    "print(\"Predicted Character:\", predicted_character[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "editor-stabilizer\n",
    "editor-editor\n",
    "analyst-editor\n",
    "Encourager-Encourager\n",
    "Initiator-Skeptic?\n",
    "Stabilizer-Stabilizer\n",
    "Driver-Architect\n",
    "Captain-Architect\n",
    "Encourager-Encourager\n",
    "Analyst-Stabilizer\n",
    "Initiator-Influencer\n",
    "Encourager-Supporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine_learning_1st_attempt_60k.joblib']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_filename = 'machine_learning_1st_attempt_60k.joblib'\n",
    "joblib.dump(clf, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "loaded_model = joblib.load('machine_learning_1st_attempt.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26809369951534734\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29      1142\n",
      "           1       0.25      0.21      0.23       437\n",
      "           2       0.24      0.17      0.20       404\n",
      "           3       0.23      0.26      0.25       816\n",
      "           4       0.26      0.23      0.25       539\n",
      "           5       0.35      0.48      0.40      1395\n",
      "           6       0.25      0.31      0.28       862\n",
      "           7       0.24      0.26      0.25       877\n",
      "           8       0.25      0.25      0.25       636\n",
      "           9       0.24      0.19      0.22       485\n",
      "          10       0.21      0.20      0.20       683\n",
      "          11       0.27      0.26      0.26       905\n",
      "          12       0.22      0.14      0.17       547\n",
      "          13       0.25      0.22      0.23       760\n",
      "          14       0.29      0.27      0.28      1048\n",
      "          15       0.26      0.21      0.23       844\n",
      "\n",
      "    accuracy                           0.27     12380\n",
      "   macro avg       0.26      0.25      0.25     12380\n",
      "weighted avg       0.26      0.27      0.26     12380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "data=pd.read_csv(\"./last_60k_with_chars.csv\")\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Preprocess text data using spaCy for tokenization\n",
    "def tokenize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.text for token in doc])\n",
    "X = data[['position 1', 'position 2', 'field of studies 1', 'field of studies 2',\n",
    "          'degree 1', 'degree 2', 'industry', 'skills',  'summary']]\n",
    "y = data['characters']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply label encoding to the target variable for both training and testing sets\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Tokenize and TF-IDF Vectorization\n",
    "X_train['tokenized_text'] = X_train.apply(lambda row: tokenize_text(\" \".join(row.astype(str))), axis=1)\n",
    "X_test['tokenized_text'] = X_test.apply(lambda row: tokenize_text(\" \".join(row.astype(str))), axis=1)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['tokenized_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['tokenized_text'])\n",
    "\n",
    "# Create and train an XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "xgb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>characters</th>\n",
       "      <th>position 1</th>\n",
       "      <th>position 2</th>\n",
       "      <th>field of studies 1</th>\n",
       "      <th>field of studies 2</th>\n",
       "      <th>degree 1</th>\n",
       "      <th>degree 2</th>\n",
       "      <th>industry</th>\n",
       "      <th>skills</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Encourager</td>\n",
       "      <td>Docent Nederlands</td>\n",
       "      <td>Auteur</td>\n",
       "      <td>Opleiding leraar Nederlands in de eerste graad</td>\n",
       "      <td>Nederlandse taal- en letterkunde</td>\n",
       "      <td>Master</td>\n",
       "      <td>Master of Arts - MA</td>\n",
       "      <td>Primary/Secondary Education</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Counselor</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>bestuurslid (secretaris)</td>\n",
       "      <td>Comparative Literature</td>\n",
       "      <td>English Language and Literature/Letters</td>\n",
       "      <td>Research master</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information Technology &amp; Services</td>\n",
       "      <td>['Academic Writing', 'English Literature', 'Li...</td>\n",
       "      <td>Bij Infi ben ik verantwoordelijk voor het verz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Verkoopmedewerker</td>\n",
       "      <td>Bemonsteraar</td>\n",
       "      <td>Algemene literatuurwetenschap</td>\n",
       "      <td>Office Management</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Associate's degree</td>\n",
       "      <td>Apparel &amp; Fashion</td>\n",
       "      <td>['Engels', 'Marketing', 'Communicatie', 'Analy...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Harmonizer</td>\n",
       "      <td>Directeur</td>\n",
       "      <td>Adviseur</td>\n",
       "      <td>International Relations and Affairs</td>\n",
       "      <td>Literature</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Performing Arts</td>\n",
       "      <td>['Journalism', 'Editing', 'Politics', 'Copywri...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Counselor</td>\n",
       "      <td>Content marketeer</td>\n",
       "      <td>Interim team lead &amp; web content editor</td>\n",
       "      <td>Letterkunde - Literair Bedrijf</td>\n",
       "      <td>Algemene Cultuurwetenschappen</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Internet</td>\n",
       "      <td>['Editing', 'Social Media', 'Dutch', 'Journali...</td>\n",
       "      <td>Creatieve contentmarketeer met een passie voor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  characters         position 1  \\\n",
       "0           0  Encourager  Docent Nederlands   \n",
       "1           1   Counselor         HR Manager   \n",
       "2           2      Driver  Verkoopmedewerker   \n",
       "3           3  Harmonizer          Directeur   \n",
       "4           4   Counselor  Content marketeer   \n",
       "\n",
       "                               position 2  \\\n",
       "0                                  Auteur   \n",
       "1                bestuurslid (secretaris)   \n",
       "2                            Bemonsteraar   \n",
       "3                                Adviseur   \n",
       "4  Interim team lead & web content editor   \n",
       "\n",
       "                               field of studies 1  \\\n",
       "0  Opleiding leraar Nederlands in de eerste graad   \n",
       "1                          Comparative Literature   \n",
       "2                   Algemene literatuurwetenschap   \n",
       "3             International Relations and Affairs   \n",
       "4                  Letterkunde - Literair Bedrijf   \n",
       "\n",
       "                        field of studies 2           degree 1  \\\n",
       "0         Nederlandse taal- en letterkunde             Master   \n",
       "1  English Language and Literature/Letters    Research master   \n",
       "2                        Office Management  Bachelor's degree   \n",
       "3                               Literature    Master's degree   \n",
       "4            Algemene Cultuurwetenschappen    Master's Degree   \n",
       "\n",
       "              degree 2                           industry  \\\n",
       "0  Master of Arts - MA        Primary/Secondary Education   \n",
       "1                  NaN  Information Technology & Services   \n",
       "2   Associate's degree                  Apparel & Fashion   \n",
       "3                  NaN                    Performing Arts   \n",
       "4    Bachelor's Degree                           Internet   \n",
       "\n",
       "                                              skills  \\\n",
       "0                                                 []   \n",
       "1  ['Academic Writing', 'English Literature', 'Li...   \n",
       "2  ['Engels', 'Marketing', 'Communicatie', 'Analy...   \n",
       "3  ['Journalism', 'Editing', 'Politics', 'Copywri...   \n",
       "4  ['Editing', 'Social Media', 'Dutch', 'Journali...   \n",
       "\n",
       "                                             summary  \n",
       "0                                                NaN  \n",
       "1  Bij Infi ben ik verantwoordelijk voor het verz...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  Creatieve contentmarketeer met een passie voor...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.dump(tfidf_vectorizer, open(\"vectorizer.pickle\", \"wb\")) #//Save vectorizer\n",
    "pickle.load(open(\"vectorizer.pickle\", 'rb'))    #// Load vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XGBoost_1st_attempt_60k.joblib']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_filename = 'XGBoost_1st_attempt_60k.joblib'\n",
    "joblib.dump(xgb_classifier, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=\"https://www.linkedin.com/in/korine-morgan-866542150/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korine-morgan-866542150\n"
     ]
    }
   ],
   "source": [
    "id = link.split('/')[4]\n",
    "url = \"https://api.iscraper.io/v2/profile-details\"\n",
    "\n",
    "payload = {\n",
    "    'profile_id': id,\n",
    "}\n",
    "print(id)\n",
    "headers = {\n",
    "    'X-API-KEY': 'hVSqiv11cY1W5YUawXUDLBn0jb4G5W44',\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "res=response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Research'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'profile_id': 'korine-morgan-866542150',\n",
       " 'first_name': 'Korine',\n",
       " 'last_name': 'Morgan',\n",
       " 'sub_title': 'Beleidsmedewerker bij Stichting IMD | Credible Messenger',\n",
       " 'profile_picture': 'https://media.licdn.com/dms/image/D5603AQF5UOAixUbdfA/profile-displayphoto-shrink_800_800/0/1681395630934?e=1701907200&v=beta&t=WG7jSJ7ex-BC9MYW8DiOiT6eXCR-DFu2ditHdY6jXzw',\n",
       " 'background_image': None,\n",
       " 'profile_type': 'personal',\n",
       " 'entity_urn': 'ACoAACRjEk4BNKurHs6ppOh5qsqFB5fHm-C8iBw',\n",
       " 'object_urn': 610472526,\n",
       " 'birth_date': None,\n",
       " 'summary': None,\n",
       " 'location': {'country': 'Netherlands',\n",
       "  'short': 'Amsterdam, North Holland',\n",
       "  'city': 'Amsterdam',\n",
       "  'state': 'North Holland',\n",
       "  'default': 'Amsterdam, North Holland, Netherlands'},\n",
       " 'premium': False,\n",
       " 'influencer': False,\n",
       " 'treasury_media': [],\n",
       " 'languages': {'primary_locale': {'country': 'US', 'language': 'en'},\n",
       "  'supported_locales': [{'country': 'US', 'language': 'en'}],\n",
       "  'profile_languages': []},\n",
       " 'industry': 'Research',\n",
       " 'education': [{'date': {'start': {'month': None, 'day': None, 'year': 2014},\n",
       "    'end': {'month': None, 'day': None, 'year': 2018}},\n",
       "   'school': {'name': 'University of Amsterdam',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C4E0BAQEfHBj_we-_kw/company-logo_400_400/0/1659945104460?e=1704931200&v=beta&t=vlWVWwukK2GuSqnOXjU-_YEQ39gihjm8OuEbRcBTBoY',\n",
       "    'url': 'https://www.linkedin.com/school/university-of-amsterdam/'},\n",
       "   'degree_name': None,\n",
       "   'field_of_study': 'Sociale wetenschappen',\n",
       "   'grade': None},\n",
       "  {'date': {'start': {'month': None, 'day': None, 'year': 2017},\n",
       "    'end': {'month': None, 'day': None, 'year': 2018}},\n",
       "   'school': {'name': 'Utrecht University',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C510BAQG6HfmPTdJKXw/company-logo_400_400/0/1519884681258?e=1704931200&v=beta&t=nayudL7KVgX2gCsqh8TSsBeGbpJTOa6ZckyNstQgIFk',\n",
       "    'url': 'https://www.linkedin.com/school/universiteit-utrecht/'},\n",
       "   'degree_name': None,\n",
       "   'field_of_study': 'Criminologie',\n",
       "   'grade': None},\n",
       "  {'date': {'start': {'month': None, 'day': None, 'year': 2013},\n",
       "    'end': {'month': None, 'day': None, 'year': 2014}},\n",
       "   'school': {'name': 'Amsterdam University of Applied Sciences',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C4E0BAQG5N3LiFgKyuA/company-logo_400_400/0/1659945616039?e=1704931200&v=beta&t=crLLaLFleGVsWremazK9JW3opXTlt2SAo-hQ30LnzuM',\n",
       "    'url': 'https://www.linkedin.com/school/hogeschool-van-amsterdam/'},\n",
       "   'degree_name': None,\n",
       "   'field_of_study': 'Maatschappelijk werk\\xa0',\n",
       "   'grade': None}],\n",
       " 'patents': [],\n",
       " 'awards': [],\n",
       " 'certifications': [],\n",
       " 'organizations': [],\n",
       " 'projects': [],\n",
       " 'publications': [],\n",
       " 'courses': [],\n",
       " 'test_scores': [],\n",
       " 'position_groups': [{'company': {'id': 18940528,\n",
       "    'name': 'Stichting IMD',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C4E0BAQGlo4QhENqaFQ/company-logo_400_400/0/1623751491624?e=1704931200&v=beta&t=ZgPWAwwdD_RPp0fDnKNZKPsbOelJRl1EChDPDp8gsqk',\n",
       "    'url': 'https://www.linkedin.com/company/stichting-imd/',\n",
       "    'employees': {'start': 11, 'end': 50}},\n",
       "   'date': {'start': {'month': 12, 'day': None, 'year': 2022},\n",
       "    'end': {'month': None, 'day': None, 'year': None}},\n",
       "   'profile_positions': [{'location': None,\n",
       "     'date': {'start': {'month': 12, 'day': None, 'year': 2022},\n",
       "      'end': {'month': None, 'day': None, 'year': None}},\n",
       "     'company': 'Stichting IMD',\n",
       "     'description': 'Stichting IMD is een jonge en innovatieve organisatie op het gebied van preventieve jeugdhulp. Met een team professionele begeleiders helpen wij jongeren in heel Amsterdam. Dankzij onze unieke methodiek en kleinschalige aanpak bereiken we jongeren met uiteenlopende uitdagingen.\\n\\nEen belangrijk doel van IMD is om vroegtijdig hulp te bieden aan jongeren. Het maakt niet uit hoe groot de hulpvraag is van het individu. IMD staat altijd klaar voor alle jongeren.',\n",
       "     'title': 'Beleidsmedewerker',\n",
       "     'employment_type': 'Part-time'}]},\n",
       "  {'company': {'id': 79970331,\n",
       "    'name': 'ADAMAS Amsterdam',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C4E0BAQHjFeD9SQTxhA/company-logo_400_400/0/1638267837456?e=1704931200&v=beta&t=E9FTIWYgsbL5CcBsC4z41pI3DHxoNtI_Tc5PeD0jctM',\n",
       "    'url': 'https://www.linkedin.com/company/adamas-amsterdam/',\n",
       "    'employees': {'start': 11, 'end': 50}},\n",
       "   'date': {'start': {'month': 9, 'day': None, 'year': 2021},\n",
       "    'end': {'month': None, 'day': None, 'year': None}},\n",
       "   'profile_positions': [{'location': 'Amsterdam, North Holland, Netherlands',\n",
       "     'date': {'start': {'month': 9, 'day': None, 'year': 2021},\n",
       "      'end': {'month': None, 'day': None, 'year': None}},\n",
       "     'company': 'ADAMAS Amsterdam',\n",
       "     'description': \"Credible messengers zijn personen die in staat zijn om bewoners en gemeenschappen te 'openen', negatief gedrag te benoemen, en mensen te motiveren tot ander gedrag of hen in ieder geval een spiegel voor te houden. \\n\\nDat doen zij in gesprek, ondersteund door gesprekstechnieken, hun voorkomen en hun ervaring, 'know how' of door hun positie in de gemeenschap. Zo kunnen zij een gids zijn voor personen die in aanraking zijn of komen met drugshandel en -criminaliteit. Ook kunnen ze waar nodig een brug vormen naar hulp en ondersteuning. \\n\\nDoel: \\nAls onderdeel van de wijkaanpak (in Zuidoost en Nieuw West, maar ook in andere stadsdelen)\\nworden credible messengers (werktitel) ingezet om jongeren die in aanraking komen met\\ndrugshandel en — criminaliteit te motiveren tot ander gedrag\",\n",
       "     'title': 'Credible Messenger',\n",
       "     'employment_type': None}]},\n",
       "  {'company': {'id': 409553,\n",
       "    'name': 'Humanitas DMH',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C4E0BAQF2CFkb4qVcvw/company-logo_400_400/0/1679998958474?e=1704931200&v=beta&t=8GG6DY28Ro2jozQddqHlc-9kLvpg0UqCM1MsnkvWwgQ',\n",
       "    'url': 'https://www.linkedin.com/company/humanitas-dmh/',\n",
       "    'employees': {'start': 1001, 'end': 5000}},\n",
       "   'date': {'start': {'month': 5, 'day': None, 'year': 2022},\n",
       "    'end': {'month': 11, 'day': None, 'year': 2022}},\n",
       "   'profile_positions': [{'location': 'Amsterdam, North Holland, Netherlands',\n",
       "     'date': {'start': {'month': 5, 'day': None, 'year': 2022},\n",
       "      'end': {'month': 11, 'day': None, 'year': 2022}},\n",
       "     'company': 'Humanitas DMH',\n",
       "     'description': None,\n",
       "     'title': 'Trajectbegeleider Forensische Zorg/Wmo',\n",
       "     'employment_type': 'Part-time'}]},\n",
       "  {'company': {'id': 8311,\n",
       "    'name': 'Gemeente Den Haag',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C4E0BAQHY6l4GYCXMdA/company-logo_400_400/0/1531139868136?e=1704931200&v=beta&t=Tv6Lx8NCK2LVyndP6SlMVArNxrhYqh6OV7dLYJmYMpg',\n",
       "    'url': 'https://www.linkedin.com/company/gemeente-den-haag/',\n",
       "    'employees': {'start': 5001, 'end': 10000}},\n",
       "   'date': {'start': {'month': 12, 'day': None, 'year': 2021},\n",
       "    'end': {'month': 5, 'day': None, 'year': 2022}},\n",
       "   'profile_positions': [{'location': 'Den Haag',\n",
       "     'date': {'start': {'month': 12, 'day': None, 'year': 2021},\n",
       "      'end': {'month': 5, 'day': None, 'year': 2022}},\n",
       "     'company': 'Gemeente Den Haag',\n",
       "     'description': None,\n",
       "     'title': 'Projectondersteuner Technologie',\n",
       "     'employment_type': 'Part-time'}]},\n",
       "  {'company': {'id': 551840,\n",
       "    'name': 'University of Humanistic Studies',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C560BAQEbp2jx4gFhRQ/company-logo_400_400/0/1519886175434?e=1704931200&v=beta&t=cCzTD9x2MWEmT_bMfJD6nsCTyaKJIcvz28GYXryZW4A',\n",
       "    'url': 'https://www.linkedin.com/school/universiteitvoorhumanistiek/',\n",
       "    'employees': {'start': 51, 'end': 200}},\n",
       "   'date': {'start': {'month': 9, 'day': None, 'year': 2021},\n",
       "    'end': {'month': 11, 'day': None, 'year': 2021}},\n",
       "   'profile_positions': [{'location': 'Utrecht, Netherlands',\n",
       "     'date': {'start': {'month': 9, 'day': None, 'year': 2021},\n",
       "      'end': {'month': 11, 'day': None, 'year': 2021}},\n",
       "     'company': 'University of Humanistic Studies',\n",
       "     'description': 'In opdracht van de gemeente Rotterdam is in september en oktober 2021 een uitgebreid\\nliteratuuronderzoek verricht naar de factor ‘Sociale relaties’ binnen het door de gemeente\\nontwikkelde ‘Rotterdams Factorenmodel’. Het Rotterdams Factorenmodel laat zien welke factoren\\nbijdragen aan het kansrijk, veilig en gezond leven van mensen in verschillende levensfasen,\\n en hoe ze daarop van invloed zijn. \\n\\nDoel van dit literatuuronderzoek is inzicht te bieden in de invloed van de\\nfactor ‘Sociale relaties’ op andere factoren die invloed hebben op de kansen, veiligheid en\\ngezondheid van mensen in verschillende levensfasen, alsmede in de risicofactoren en beschermende\\nof versterkende factoren op dit gebied.',\n",
       "     'title': 'Onderzoeksassistent',\n",
       "     'employment_type': None}]},\n",
       "  {'company': {'id': 56461466,\n",
       "    'name': 'Cyvitas',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C4D0BAQG0vr-eLymjjQ/company-logo_400_400/0/1592481633861?e=1704931200&v=beta&t=NTZizlPEx8NvBp6SXaTGV9JGUznOxixBB0rBYnI1HkI',\n",
       "    'url': 'https://www.linkedin.com/company/cyvitas/',\n",
       "    'employees': {'start': 2, 'end': 10}},\n",
       "   'date': {'start': {'month': 2, 'day': None, 'year': 2020},\n",
       "    'end': {'month': 8, 'day': None, 'year': 2021}},\n",
       "   'profile_positions': [{'location': None,\n",
       "     'date': {'start': {'month': 2, 'day': None, 'year': 2020},\n",
       "      'end': {'month': 8, 'day': None, 'year': 2021}},\n",
       "     'company': 'Cyvitas',\n",
       "     'description': 'Cyvitas is een start-up waarbij studenten worden betrokken bij de zorg middels een extra curriculair- of stagetraject. Tijdens dit traject verdiepen (master)studenten met ambities binnen de ouderenzorg zich in een vraagstuk binnen de ouderenzorg, waarbij ze een oplossing voor een specifieke doelgroep uitwerken.',\n",
       "     'title': 'Project Manager',\n",
       "     'employment_type': None}]},\n",
       "  {'company': {'id': 14005106,\n",
       "    'name': 'Gebrouwen door Vrouwen BAR',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C4D0BAQFM_a06d5hboQ/company-logo_400_400/0/1552203910904?e=1704931200&v=beta&t=B-LcYtOdNIHIk2l_Qd8IKCSlMxCoT8B17VmjQjwMeDM',\n",
       "    'url': 'https://www.linkedin.com/company/gebrouwen-door-vrouwen-bar/',\n",
       "    'employees': {'start': 11, 'end': 50}},\n",
       "   'date': {'start': {'month': 3, 'day': None, 'year': 2019},\n",
       "    'end': {'month': 3, 'day': None, 'year': 2020}},\n",
       "   'profile_positions': [{'location': 'Amsterdam',\n",
       "     'date': {'start': {'month': 3, 'day': None, 'year': 2019},\n",
       "      'end': {'month': 3, 'day': None, 'year': 2020}},\n",
       "     'company': 'Gebrouwen door Vrouwen BAR',\n",
       "     'description': None,\n",
       "     'title': 'Bartender',\n",
       "     'employment_type': 'Part-time'}]},\n",
       "  {'company': {'id': 4083,\n",
       "    'name': 'VUmc',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C4E0BAQHBs6rXsQYqGQ/company-logo_400_400/0/1528382070277?e=1704931200&v=beta&t=uhy44KF8zCn-qPQzwXzgJcMBXsIrTPEOVZPuXCvDzWI',\n",
       "    'url': 'https://www.linkedin.com/company/amsterdamumc/',\n",
       "    'employees': {'start': 10001, 'end': None}},\n",
       "   'date': {'start': {'month': 11, 'day': None, 'year': 2014},\n",
       "    'end': {'month': 7, 'day': None, 'year': 2015}},\n",
       "   'profile_positions': [{'location': None,\n",
       "     'date': {'start': {'month': 11, 'day': None, 'year': 2014},\n",
       "      'end': {'month': 7, 'day': None, 'year': 2015}},\n",
       "     'company': 'Amsterdam UMC',\n",
       "     'description': 'Afdeling Sociale geneeskunde',\n",
       "     'title': 'Onderzoeksassistent',\n",
       "     'employment_type': None}]},\n",
       "  {'company': {'id': 843906,\n",
       "    'name': \"School's cool Nederland\",\n",
       "    'logo': 'https://media.licdn.com/dms/image/C4D0BAQGwPjnPn3zdSA/company-logo_400_400/0/1616420447563?e=1704931200&v=beta&t=worYoBU0YTZdQjpvYJLdioQkgudsmrbxxDffV-TO68g',\n",
       "    'url': \"https://www.linkedin.com/company/school's-cool_2/\",\n",
       "    'employees': {'start': 51, 'end': 200}},\n",
       "   'date': {'start': {'month': 11, 'day': None, 'year': 2013},\n",
       "    'end': {'month': 6, 'day': None, 'year': 2014}},\n",
       "   'profile_positions': [{'location': None,\n",
       "     'date': {'start': {'month': 11, 'day': None, 'year': 2013},\n",
       "      'end': {'month': 6, 'day': None, 'year': 2014}},\n",
       "     'company': \"School's cool Nederland\",\n",
       "     'description': None,\n",
       "     'title': 'Vrijwilliger',\n",
       "     'employment_type': None}]}],\n",
       " 'volunteer_experiences': [],\n",
       " 'skills': [],\n",
       " 'network_info': None,\n",
       " 'related_profiles': None,\n",
       " 'contact_info': None}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Criminologie'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['education'][1]['field_of_study']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\programming\\GitHub\\Bots with Selenium\\Bots_using_selenium\\model_crystal\\train_model.ipynb Cell 25\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     industries\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mUnknown\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m user_input \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mposition 1\u001b[39;49m\u001b[39m'\u001b[39;49m: positions0[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mposition 2\u001b[39;49m\u001b[39m'\u001b[39;49m: positions1[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mfield of studies 1\u001b[39;49m\u001b[39m'\u001b[39;49m: field_of_studies0[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mfield of studies 2\u001b[39;49m\u001b[39m'\u001b[39;49m: field_of_studies1[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mdegree 1\u001b[39;49m\u001b[39m'\u001b[39;49m:degrees0[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mdegree 2\u001b[39;49m\u001b[39m'\u001b[39;49m:degrees1[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mindustry\u001b[39;49m\u001b[39m'\u001b[39;49m: industries[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mskills\u001b[39;49m\u001b[39m'\u001b[39;49m: skills[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m })\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# user_input['tokenized_text'] = user_input.apply(lambda row: tokenize_text(\" \".join(row.astype(str))), axis=1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# # TF-IDF Vectorization for user input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m# dict_[i]=predicted_character\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/programming/GitHub/Bots%20with%20Selenium/Bots_using_selenium/model_crystal/train_model.ipynb#X25sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m# dict_list.append(dict_)\u001b[39;00m\n",
      "File \u001b[1;32md:\\programming\\GitHub\\Bots with Selenium\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:736\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    730\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    731\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    732\u001b[0m     )\n\u001b[0;32m    734\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    735\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    737\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    738\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32md:\\programming\\GitHub\\Bots with Selenium\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32md:\\programming\\GitHub\\Bots with Selenium\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32md:\\programming\\GitHub\\Bots with Selenium\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:667\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m indexes \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 667\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf using all scalar values, you must pass an index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    669\u001b[0m \u001b[39mif\u001b[39;00m have_series:\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "positions0=[]\n",
    "positions1=[]\n",
    "skills=[]\n",
    "field_of_studies0=[]\n",
    "field_of_studies1=[]\n",
    "degrees0=[]\n",
    "degrees1=[]\n",
    "industries=[]\n",
    "summaries=[]\n",
    "if res['skills']:\n",
    "    skills.append(res['skills'])\n",
    "else:\n",
    "    skills.append(\"NaN\")\n",
    "    print(\"HI\")\n",
    "if res['position_groups'][0]['profile_positions'][0]['title']:\n",
    "    position0=res['position_groups'][0]['profile_positions'][0]['title']\n",
    "    positions0.append(position0)\n",
    "else:\n",
    "    positions0.append(\"NaN\")\n",
    "try:\n",
    "    position1=res['position_groups'][1]['profile_positions'][0]['title']\n",
    "    positions1.append(position1)\n",
    "except:\n",
    "    positions1.append(\"NaN\")\n",
    "try:\n",
    "    field_of_study0=res['education'][0]['field_of_study']\n",
    "    field_of_studies0.append(field_of_study0)\n",
    "except:\n",
    "    field_of_studies0.append(\"NaN\")\n",
    "try:\n",
    "    field_of_study1=res['education'][1]['field_of_study']\n",
    "    field_of_studies1.append(field_of_study1)\n",
    "except:\n",
    "    field_of_studies1.append(\"NaN\")\n",
    "try:\n",
    "    degree_name0=res['education'][0]['degree_name']\n",
    "    degrees0.append(degree_name0)\n",
    "except:\n",
    "    degrees0.append(\"NaN\")\n",
    "try:\n",
    "    degree_name1=res['education'][1]['degree_name']\n",
    "    degrees1.append(degree_name1)\n",
    "except:\n",
    "    degrees1.append(\"NaN\")\n",
    "try:\n",
    "    summaries.append(res['summary'])\n",
    "except:\n",
    "    summaries.append(\"NaN\")\n",
    "try:\n",
    "    industries.append(res['industry'])\n",
    "except:\n",
    "    industries.append(\"NaN\")\n",
    "\n",
    "user_input = pd.DataFrame({\n",
    "    'position 1': positions0[0],\n",
    "    'position 2': positions1[0],\n",
    "    'field of studies 1': field_of_studies0[0],\n",
    "    'field of studies 2': field_of_studies1[0],\n",
    "    'degree 1':degrees0[0],\n",
    "    'degree 2':degrees1[0],\n",
    "    'industry': industries[0],\n",
    "    'skills': skills[0],\n",
    "})\n",
    "# user_input['tokenized_text'] = user_input.apply(lambda row: tokenize_text(\" \".join(row.astype(str))), axis=1)\n",
    "\n",
    "# # TF-IDF Vectorization for user input\n",
    "# user_input_tfidf = tfidf_vectorizer.transform(user_input['tokenized_text'])\n",
    "\n",
    "# # Predict the character for the user input\n",
    "# predicted_character = xgb_classifier.predict(user_input_tfidf)\n",
    "\n",
    "# # print(\"Predicted Character:\", label_encoder.inverse_transform(predicted_character)[0])\n",
    "# dict_[i]=predicted_character\n",
    "# dict_list.append(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NaN']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position 1</th>\n",
       "      <th>position 2</th>\n",
       "      <th>field of studies 1</th>\n",
       "      <th>field of studies 2</th>\n",
       "      <th>degree 1</th>\n",
       "      <th>degree 2</th>\n",
       "      <th>industry</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [position 1, position 2, field of studies 1, field of studies 2, degree 1, degree 2, industry, skills]\n",
       "Index: []"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beleidsmedewerker'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['position_groups'][0]['profile_positions'][0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position 1</th>\n",
       "      <th>position 2</th>\n",
       "      <th>field of studies 1</th>\n",
       "      <th>field of studies 2</th>\n",
       "      <th>degree 1</th>\n",
       "      <th>degree 2</th>\n",
       "      <th>industry</th>\n",
       "      <th>skills</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [position 1, position 2, field of studies 1, field of studies 2, degree 1, degree 2, industry, skills, tokenized_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'profile_id': 'james-efmorfidis-0a4429209',\n",
       " 'first_name': 'James',\n",
       " 'last_name': 'Efmorfidis',\n",
       " 'sub_title': 'Soccer Player at RKC Waalwijk',\n",
       " 'profile_picture': 'https://media.licdn.com/dms/image/C4E03AQEfuZCuGu5HiA/profile-displayphoto-shrink_800_800/0/1619700178644?e=1701907200&v=beta&t=p-51YNTEmeIqkQcCLwtww-fcHQFGTfJuVMB7-4Vp3JE',\n",
       " 'background_image': 'https://media.licdn.com/dms/image/C4E16AQGMQ5VXQDbprA/profile-displaybackgroundimage-shrink_350_1400/0/1619700248345?e=1701907200&v=beta&t=KPDBl1aJXqRpgaCyxXXnhh30QdkifblmkXXp5ZXSf6o',\n",
       " 'profile_type': 'personal',\n",
       " 'entity_urn': 'ACoAADTsHzwBJq0JGszXMZKLseDfSZlmtaE-GUM',\n",
       " 'object_urn': 887889724,\n",
       " 'birth_date': None,\n",
       " 'summary': None,\n",
       " 'location': {'country': 'Netherlands',\n",
       "  'short': 'Amsterdam, North Holland',\n",
       "  'city': 'Amsterdam',\n",
       "  'state': 'North Holland',\n",
       "  'default': 'Amsterdam, North Holland, Netherlands'},\n",
       " 'premium': False,\n",
       " 'influencer': False,\n",
       " 'treasury_media': [],\n",
       " 'languages': {'primary_locale': {'country': 'US', 'language': 'en'},\n",
       "  'supported_locales': [{'country': 'US', 'language': 'en'}],\n",
       "  'profile_languages': []},\n",
       " 'industry': 'Sports',\n",
       " 'education': [],\n",
       " 'patents': [],\n",
       " 'awards': [],\n",
       " 'certifications': [],\n",
       " 'organizations': [],\n",
       " 'projects': [],\n",
       " 'publications': [],\n",
       " 'courses': [],\n",
       " 'test_scores': [],\n",
       " 'position_groups': [{'company': {'id': 549880,\n",
       "    'name': 'RKC Waalwijk',\n",
       "    'logo': 'https://media.licdn.com/dms/image/C4D0BAQEC_cbNl3HLhg/company-logo_400_400/0/1531133812048?e=1704931200&v=beta&t=A6a7LjDR5mBJT5MtV3JcSewqRe9vTqWOLk5C0uZYGRs',\n",
       "    'url': 'https://www.linkedin.com/company/rkc-waalwijk/',\n",
       "    'employees': {'start': 11, 'end': 50}},\n",
       "   'date': {'start': {'month': 7, 'day': None, 'year': 2020},\n",
       "    'end': {'month': None, 'day': None, 'year': None}},\n",
       "   'profile_positions': [{'location': None,\n",
       "     'date': {'start': {'month': 7, 'day': None, 'year': 2020},\n",
       "      'end': {'month': None, 'day': None, 'year': None}},\n",
       "     'company': 'RKC Waalwijk',\n",
       "     'description': None,\n",
       "     'title': 'Soccer Player',\n",
       "     'employment_type': 'Full-time'}]}],\n",
       " 'volunteer_experiences': [],\n",
       " 'skills': [],\n",
       " 'network_info': None,\n",
       " 'related_profiles': None,\n",
       " 'contact_info': None}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{33: array([15, 15, 15, 15, 15, 15, 15,  6], dtype=int64)}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_list[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Planner', 'Counselor', 'Harmonizer', 'Planner', 'Planner',\n",
       "       'Counselor', 'Planner', 'Planner', 'Planner', 'Planner', 'Planner',\n",
       "       'Planner', 'Planner', 'Planner', 'Planner'], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform(dict_list[25][26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3:counselor\n",
    "6:Encourager\n",
    "7:Harmonizer\n",
    "8:Influencer\n",
    "9:Initiator\n",
    "10:Motivator\n",
    "11:Planner\n",
    "15:supporter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Motivator', 'Harmonizer', 'Harmonizer', 'Initiator', 'Harmonizer',\n",
       "       'Counselor', 'Harmonizer', 'Harmonizer', 'Motivator', 'Influencer',\n",
       "       'Harmonizer', 'Encourager', 'Motivator', 'Motivator', 'Harmonizer',\n",
       "       'Initiator', 'Motivator', 'Harmonizer', 'Harmonizer', 'Motivator'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform(predicted_character)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
