{
    "profile_id": "mohammed-aala-9105827",
    "first_name": "Mohammed",
    "last_name": "Aala",
    "sub_title": "Azure Data Engineer || Data Warehouse Architect/Developer || Business Intelligence Developer",
    "profile_picture": null,
    "background_image": null,
    "profile_type": "personal",
    "entity_urn": "ACoAAAFUhpwBHoPjzFezm40cBgIZ6ngUTYQThVg",
    "object_urn": 22316700,
    "birth_date": null,
    "summary": "Self-directed and driven Business Intelligence/Data Warehouse developer  with comprehensive accomplishments applying propensity modeling, data migration followed by transformation and data visualization to ensure success and achieve goals. Known as an innovative thinker with strong SQL, ETL & reporting skills. Demonstrated success developing and seamlessly executing plans across complex data sets. Inject analytical rigor, scalable data architecture and latest cutting-edge technologies to continually improve and add value for cross-functional business team. Recognized for maximizing performance by implementing appropriate data analysis and business workflows to ensure quality control, legacy system data migration and transformation and understanding of emerging technology. Highly organized, creative problem solver who excels at producing business value by applying data analytics best practices to challenging problems.\n\nAccomplishments:\n\u2022\tPrepare and transform regulatory reporting data into Wolters Kluwer's data foundation environment for monthly reports and operational performance forecasts.\n\u2022\tUpdated project documents regarding technical details, user expectation, goals, work effort accountability and deliverables.\n\u2022\tEvaluate performance enhancement and troubleshooting assignments, including smooth data transition, and checking alert logs.\n\u2022\tCollaborated with the end users to identify technical requirements for the development project based on their business requirements. \n\u2022\tDevised a way to develop dashboard design/analysis approach by communicating with all business users with use case statements.\n\nExpertise:\nBusiness Intelligence, Data Warehouse, Extract Transform Load [ETL], Business Analysis, Data Modeling, Data Migration, Data Transformation, Data Visualization, Data Analysis, Unit Testing, Requirement Analysis, Data Vault, Data Marts, Master Data Services, Enterprise Data Warehouse [EDW], Regulatory Reporting, Enterprise Resource Planning [ERP], Financial Reporting, Integration, SAP Business Objects [Crystal Reports], SAP Business One, Qlik Replicate [Attunity] & SQL Server",
    "location": {
        "country": "Netherlands",
        "short": "Amsterdam, North Holland",
        "city": "Amsterdam",
        "state": "North Holland",
        "default": "Amsterdam, North Holland, Netherlands"
    },
    "premium": true,
    "influencer": false,
    "treasury_media": [],
    "languages": {
        "primary_locale": {
            "country": "US",
            "language": "en"
        },
        "supported_locales": [
            {
                "country": "US",
                "language": "en"
            }
        ],
        "profile_languages": [
            {
                "name": "Arabic",
                "proficiency": "LIMITED_WORKING"
            },
            {
                "name": "Dutch",
                "proficiency": "ELEMENTARY"
            },
            {
                "name": "English",
                "proficiency": "PROFESSIONAL_WORKING"
            },
            {
                "name": "Hindi",
                "proficiency": "FULL_PROFESSIONAL"
            },
            {
                "name": "Oriya",
                "proficiency": "FULL_PROFESSIONAL"
            },
            {
                "name": "Telugu",
                "proficiency": "LIMITED_WORKING"
            },
            {
                "name": "Urdu",
                "proficiency": "FULL_PROFESSIONAL"
            }
        ]
    },
    "industry": "Information Technology & Services",
    "education": [
        {
            "date": {
                "start": {
                    "month": null,
                    "day": null,
                    "year": 2002
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": 2006
                }
            },
            "school": {
                "name": "Biju Patnaik University of Technology, Odisha",
                "logo": "https://media.licdn.com/dms/image/C4E0BAQEaduRrmJ3icw/company-logo_400_400/0/1519873721603?e=1703721600&v=beta&t=XNptlnLaNkbrKy8DsQuPxbubjsP7NqLkDilHexepgUA",
                "url": "https://www.linkedin.com/school/biju-patnaik-university-of-technology-odisha/"
            },
            "degree_name": "Bachelors of Technology (B.Tech.)",
            "field_of_study": "Computer Science",
            "grade": "A"
        },
        {
            "date": {
                "start": {
                    "month": null,
                    "day": null,
                    "year": 1998
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": 2000
                }
            },
            "school": {
                "name": "Capital High School, Bhubaneswar, Odisha",
                "logo": null,
                "url": null
            },
            "degree_name": "10th",
            "field_of_study": "General Studies",
            "grade": "First Class"
        }
    ],
    "patents": [],
    "awards": [],
    "certifications": [
        {
            "name": "36Hrs PMP Exam Preparation Certification",
            "date": {
                "start": {
                    "month": null,
                    "day": null,
                    "year": null
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "authority": "CMS Riyadh",
            "url": null,
            "license_number": null,
            "display_source": null,
            "company": null
        }
    ],
    "organizations": [
        {
            "name": "Pune Softies, Mumbai Softies, Hyderabad Softies, Other IT Groups",
            "position": "No",
            "date_start": {
                "month": 8,
                "day": null,
                "year": 2006
            },
            "date_end": null
        }
    ],
    "projects": [],
    "publications": [],
    "courses": [
        {
            "name": "Computer Diploma in Information Science",
            "number": null
        }
    ],
    "test_scores": [],
    "position_groups": [
        {
            "company": {
                "id": 5042,
                "name": "Emirates",
                "logo": "https://media.licdn.com/dms/image/C4D0BAQH4KZK4uVN0qg/company-logo_400_400/0/1633591045876?e=1703721600&v=beta&t=Smnelmb-DrVsMC9aF0Xxf0dU83qZSPbnnEjIQcat8-0",
                "url": "https://www.linkedin.com/company/emirates/",
                "employees": {
                    "start": 10001,
                    "end": null
                }
            },
            "date": {
                "start": {
                    "month": 1,
                    "day": null,
                    "year": 2023
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "profile_positions": [
                {
                    "location": "Dubai, United Arab Emirates",
                    "date": {
                        "start": {
                            "month": 1,
                            "day": null,
                            "year": 2023
                        },
                        "end": {
                            "month": null,
                            "day": null,
                            "year": null
                        }
                    },
                    "company": "Emirates",
                    "description": "1. Extract Transform and Load data from Sources Systems to Azure Data Storage services using a combination of Azure Data Factory, T-SQL, Spark SQL and U-SQL Azure Data Lake Analytics . Data Ingestion to one or more Azure Services - (Azure Data Lake, Azure Storage, Azure SQL, Azure DW) and processing the data in In Azure Databricks.\n2. Created Pipelines in ADF using Linked Services/Datasets/Pipeline/ to Extract, Transform and load data from different sources like Bigdata cluster [Helix], Blob storage, Oracle, write-back tool and backwards.\n3. Developed Spark applications using Pyspark and Spark-SQL for data extraction, transformation and aggregation from multiple file formats for analyzing &amp; transforming the data to uncover insights into the customer usage patterns.\n4. Implemented the data migration activity both for historical & incremental load across different layers.\n5. Developed JSON Scripts for deploying the Pipeline in Azure Data Factory (ADF) that process the data using the Sql Activity.\n6. Implemented Azure Logic Apps and Functions to automate business processes and improve efficiency.\n7. Responsible for estimating the cluster size, monitoring and troubleshooting of the Spark databricks cluster.\n8. Hands-on experience on developing SQL Scripts for automation purpose.\n9. Collaborated with business leaders to define requirements and translate them into technical solutions.\n10. Maintained technical documentation and led BI solution design sessions, integrations, configurations, and other interface documentation.\n11. Deployed Co-coordinators from CDH [Cloudera data hub] to CDP [Cloudera data platform] using Azure DevOps & tested the workflows using Oozie Framework.\n12. Created Build and Release for multiple projects (modules) in production environment using Azure DevOps tool.",
                    "title": "Senior Data Engineer",
                    "employment_type": "Permanent"
                }
            ]
        },
        {
            "company": {
                "id": 11262301,
                "name": "Bolders Consulting Group",
                "logo": "https://media.licdn.com/dms/image/C4E0BAQFCGmRunBjYzA/company-logo_400_400/0/1592379885530?e=1703721600&v=beta&t=Ij7KWj5WCLafDY0kbqtsuCWCGXgLiaX7fszAnsxHprQ",
                "url": "https://www.linkedin.com/company/boldersconsultinggroup/",
                "employees": {
                    "start": 11,
                    "end": 50
                }
            },
            "date": {
                "start": {
                    "month": 12,
                    "day": null,
                    "year": 2020
                },
                "end": {
                    "month": 12,
                    "day": null,
                    "year": 2022
                }
            },
            "profile_positions": [
                {
                    "location": "Amsterdam, North Holland, Netherlands",
                    "date": {
                        "start": {
                            "month": 12,
                            "day": null,
                            "year": 2020
                        },
                        "end": {
                            "month": 12,
                            "day": null,
                            "year": 2022
                        }
                    },
                    "company": "Bolders Consulting Group",
                    "description": "\u2022 Designed and architected scalable data processing and analytics solutions, including technical feasibility, integration, development for Azure blob storage, processing and consumption of Azure data,\nanalytics, business intelligence (Reporting Services, Power BI), Azure Data Factory, Event Hubs and Notification Hubs.\n\u2022 Developed, implemented and maintained data analytics protocols, standards and documentation.\n\u2022 Analyzed complex data and identified anomalies, trends and risks to provide useful insights to improve internal controls.\n\u2022 Extract, Transform and Load (ETL/ELT) data from Sources Systems to Azure Blob Storage services using a combination of Azure Data Factory, T-SQL, Azure Data Lake Analytics. Data Ingestion to one or more Azure Services - (Azure Data Lake, Azure Storage, Azure SQL, Azure DW) and processing the data in In Azure Data bricks & Power BI analytics tools.\n\u2022 Collaborated on ETL (Extract, Transform, Load) tasks, maintaining data integrity and verifying pipeline stability.\n\u2022 Analyzed, designed and built Modern data solutions using Azure PaaS service to support visualization of data. Understand current production state of application and determine the impact of new implementation on existing business processes.\n\u2022 Explained data results and discussed how best to use data to support project objectives.\n\u2022 Generated detailed studies on potential third-party data handling solutions, verifying compliance with internal needs and stakeholder requirements.\n\u2022 Contributed to internal activities for overall process improvements, efficiencies and innovation.\n\u2022 Designed strategies for optimizing all aspect of the continuous integration, release and deployment processes (CI/CD) using ADF pipelines and virtualization techniques using Azure DevOps resources.\n\u2022 Performed in agile methodology, interacted directly with entire team provided/took feedback on design, suggested/implemented optimal solutions, and tailored application to meet business requirements.",
                    "title": "Lead Data Engineer",
                    "employment_type": "Full-time"
                }
            ]
        },
        {
            "company": {
                "id": 9434888,
                "name": "BI Solutions Nederland",
                "logo": "https://media.licdn.com/dms/image/C4D0BAQGo4BOrJmGtpQ/company-logo_400_400/0/1519886300219?e=1703721600&v=beta&t=TL-yXO0BouV4hIF3WeQr00bWrd6y1S5q7ypATc85LwE",
                "url": "https://www.linkedin.com/company/bi-solutions-nederland/",
                "employees": {
                    "start": 2,
                    "end": 10
                }
            },
            "date": {
                "start": {
                    "month": 9,
                    "day": null,
                    "year": 2020
                },
                "end": {
                    "month": 9,
                    "day": null,
                    "year": 2020
                }
            },
            "profile_positions": [
                {
                    "location": "Haarlem, North Holland, Netherlands",
                    "date": {
                        "start": {
                            "month": 9,
                            "day": null,
                            "year": 2020
                        },
                        "end": {
                            "month": 9,
                            "day": null,
                            "year": 2020
                        }
                    },
                    "company": "BI Solutions Nederland",
                    "description": "\u2022Designed SSIS packages to extract data from different sources like Oracle ERP, Oracle\nAPIs, transform and then load into Dimension and Fact tables in Data Warehouse using\nSSIS.\n\u2022Participate in requirements, design, and development reviews. Conduct or participate\nin meetings with owners of key system components to fully understand current data\nand systems environments. Resolve source data issues and refine transformation rules.\n\u2022Identify problems, develop ideas and propose solutions within differing situations\nrequiring analytical, evaluative or constructive thinking in daily work\n\u2022Designed the ETL mapping document followed by Data Segmentation & data Storage\nprinciples with the help of FRD document.\n\u2022Analyzes day-to-day functions and processes to ensure they are performing within\npredetermined guidelines, limits, and specifications.\n\u2022Involved in end to end system Testing, Performance and regression testing and data\nvalidations and Unit Testing.\n\u2022Configured SQL jobs and maintenance plans to ensure database stability \u2022 and integrity.\nActively supported Business users for change requests and provide support to team\nmembers.\n\u2022Apply creative thinking to identify possible bottlenecks and reporting solution alternatives.\n\u2022Worked on support tickets, maintenance tasks and assigned projects at discretion of\nthe Reporting Coordinator.\n\u2022Able to work in fast-paced environment.",
                    "title": "Business Intelligence Developer",
                    "employment_type": "Full-time"
                }
            ]
        },
        {
            "company": {
                "id": 394053,
                "name": "Santander Consumer Finance Benelux B.V",
                "logo": "https://media.licdn.com/dms/image/D4E0BAQGxeH4ePLpaMA/company-logo_400_400/0/1689154437236?e=1703721600&v=beta&t=ti1OVAIrk7rWrbYBCHv9OePg59ouQSzWGiF-DpME11U",
                "url": "https://www.linkedin.com/company/santander-consumer-finance-benelux/",
                "employees": {
                    "start": 201,
                    "end": 500
                }
            },
            "date": {
                "start": {
                    "month": 6,
                    "day": null,
                    "year": 2019
                },
                "end": {
                    "month": 8,
                    "day": null,
                    "year": 2020
                }
            },
            "profile_positions": [
                {
                    "location": "Utrecht Area, Netherlands",
                    "date": {
                        "start": {
                            "month": 6,
                            "day": null,
                            "year": 2019
                        },
                        "end": {
                            "month": 8,
                            "day": null,
                            "year": 2020
                        }
                    },
                    "company": "Santander Consumer Finance Benelux",
                    "description": "\u2022 Worked with Santander's in-house data warehouse project to facilitate end to end data migration process and to generate robust financial reports in regards to ECB & DNB guidelines & regulations for Santander's Benelux region.\n\u2022 Involved in creation/review of functional design, technical design along with requirement specifications and supporting documents for business systems, experience in database design process and data modeling process.\n\u2022 Created data models and mapped content storage pathways to facilitate easy access and support troubleshooting access issues.\n\u2022 Involved in root cause analysis for existing data flow model and developed end to end solutions for the improvement of SSIS packages and also worked on performance analysis and enhancement.\n\u2022 Designed and implemented complex SSIS package to migrate data from multiple sources, different legacy systems to SQL Server databases using SQL Server Integration Services [SSIS] and stored procedures to overcome the transformation constraints.\n\u2022 Created conceptual, logical and physical models for OLTP , Data Warehouse Data Vault and Data Mart Star/Snowflake schema implementations.\n\u2022 Created multiple Links, Hubs & Satellites tables based on the functional design to load data into Enterprise Data Warehouse [EDW].\n\u2022 Built data vaults, data marts and queries, maintaining every aspect of storage and translation.\n\u2022 Documented the technical architecture of the data warehouse, including the physical components, their functionality, source data and ability to integrate with existing system architecture.\n\u2022 Handled Performance Tuning and Optimization on ETL processes and Data Vault with strong analytical and troubleshooting skills for quick issue resolution in large-scale production environments located globally.\n\u2022 Created new data flow migration steps from source to target in Qlik Replicate [Attunity] replication tools with continuous monitoring and troubleshooting of Attunity process and fixing production support issues.",
                    "title": "Senior Data Warehouse Developer",
                    "employment_type": "Permanent"
                }
            ]
        },
        {
            "company": {
                "id": 3795888,
                "name": "MUFG",
                "logo": "https://media.licdn.com/dms/image/D560BAQEyC1DyrmO5yA/company-logo_400_400/0/1688117555709?e=1703721600&v=beta&t=cXgEvlWapHXJRTfKTCMAp4iekkyRXunCPBCbQSlbMKA",
                "url": "https://www.linkedin.com/company/mufg/",
                "employees": {
                    "start": 10001,
                    "end": null
                }
            },
            "date": {
                "start": {
                    "month": 6,
                    "day": null,
                    "year": 2018
                },
                "end": {
                    "month": 3,
                    "day": null,
                    "year": 2019
                }
            },
            "profile_positions": [
                {
                    "location": "Amsterdam Area, Netherlands",
                    "date": {
                        "start": {
                            "month": 6,
                            "day": null,
                            "year": 2018
                        },
                        "end": {
                            "month": 3,
                            "day": null,
                            "year": 2019
                        }
                    },
                    "company": "MUFG",
                    "description": "\u2022Worked on \"AnaCredit\" regulatory reporting project to facilitate end to end data process and to generate robust financial reports in regards to ECB & DNB regulations.\n\u2022Analyzed requirement and impact by participating in Joint application development sessions with business.\n\u2022Designed and implemented complex SSIS package to migrate data from multiple data sources.\n\u2022Designed & implemented and integrated a new repository of data migration from different layers to Target repository.\n\u2022Worked closely with business analysts and gathered functional requirements.\n\u2022Designed technical design documents for ETL process.\n\u2022Worked closely with the Product Owner and Data Architect in design by doing source data analysis, modifying the requirement documents, creating source to Target Mappings.\n\u2022Created the deployment scripts and managed the code in Bitbucket source control.\n\u2022Designed & implemented Sql Master Data Services [MDS] for configuring the attributes and enriching the data through Data Enrichment Module [DEM] via SSIS & MDS.\n\u2022Created and scheduled SQL Agent jobs and maintenance plans.\n\u2022Modified and maintained SQL Server stored procedures, views, functions using T-SQL and SSIS packages in configuring the jobs in SQL Agent.\n\u2022Worked on data migration to target repository [Wolters Kluwer] and transforming the input data as per WK's data foundation language.\n\u2022Engaged in meetings with product owners & business users throughout development to gather system requirements from users and ensure user acceptance testing was performed.\n\u2022Involved in front line code reviews, end to end system testing, performance and regression testing and data validations and unit testing.\n\u2022Collaborated with multi-vendor global teams like business analysts, front end developers and testers.\n\u2022Worked on production support tickets, maintenance tasks and assigned projects at discretion of the reporting coordinator.\n\u2022Actively supported business users for change requests and provide support to team members.",
                    "title": "Business Intelligence Developer",
                    "employment_type": "Contract"
                }
            ]
        },
        {
            "company": {
                "id": 1318,
                "name": "Wipro",
                "logo": "https://media.licdn.com/dms/image/C4E0BAQE0UPACNUrv3g/company-logo_400_400/0/1674757963152?e=1703721600&v=beta&t=XHxDxMbtIy7BT1iDz57Gwr0FYFYFm8MYBOSP_rMxqHE",
                "url": "https://www.linkedin.com/company/wipro/",
                "employees": {
                    "start": 10001,
                    "end": null
                }
            },
            "date": {
                "start": {
                    "month": 1,
                    "day": null,
                    "year": 2017
                },
                "end": {
                    "month": 12,
                    "day": null,
                    "year": 2017
                }
            },
            "profile_positions": [
                {
                    "location": "Bengaluru Area, India",
                    "date": {
                        "start": {
                            "month": 1,
                            "day": null,
                            "year": 2017
                        },
                        "end": {
                            "month": 12,
                            "day": null,
                            "year": 2017
                        }
                    },
                    "company": "Wipro",
                    "description": "\u2022Improved data gathering, analysis and visualization procedures with strategic optimizations.\n\u2022Designed and implemented complex SSIS package to migrate data from multiple data sources.\n\u2022Developed SSIS packages to extract data from different sources i.e. rest APIs like ServiceNow , SalesForce , Sharepoint & external PMWeb tools and load into central repository data warehouse.\n\u2022Created files, views, tables and data sets to support Data Center Sales Operations and Analytics teams.\n\u2022Maintain existing QlikView Reports against legacy system and rewrite these reports in Power BI against new data warehouse.\n\u2022Designed and managed analysis reports , charts, scorecards, and dashboards using Power BI reporting tools.\n\u2022Updated existing and developed & deployed new reports using Power BI Reporting services, embedded & deployed into Sharepoint environment.\n\u2022Created the deployment scripts and managed the source code in Team Foundation Server [ TFS ].\n\u2022Automated BI reports for secure virtual \u2022 server environment.\n\u2022Generated reports, updated spreadsheets and presented results.\n\u2022Drafted strategic business intelligence road-map, complete with data governance policies and tactical information safeguards.\n\u2022Created batch files & configured jobs scheduling through windows task scheduler.\n\u2022Created Azure SQL database and migrated the on-premises existing database contents into azure database.\n\u2022Created Azure Data Factory for data storage and smooth data processing through pipelines and parallel processing.\n\u2022Designed customized data collection models for specific visualization tasks.\n\u2022Monitored and optimized SQL server performance.\n\u2022Worked closely with other business analysts, development teams and infrastructure specialists to deliver high availability solutions for mission-critical applications.\n\u2022Tested troubleshooting methods, devised innovative solutions, and documented resolutions for inclusion in knowledge base for support team use.",
                    "title": "Senior Business Intelligence Developer",
                    "employment_type": "Full-time"
                }
            ]
        },
        {
            "company": {
                "id": 202963,
                "name": "Royal Cyber Inc.",
                "logo": "https://media.licdn.com/dms/image/C4E0BAQHTM_DGX4C8nQ/company-logo_400_400/0/1594044774779?e=1703721600&v=beta&t=T09u9VUsKTWw8_lbppeW9vjGNgFWns46x2Oq0Kv_-Wc",
                "url": "https://www.linkedin.com/company/royal-cyber-inc-/",
                "employees": {
                    "start": 501,
                    "end": 1000
                }
            },
            "date": {
                "start": {
                    "month": 4,
                    "day": null,
                    "year": 2016
                },
                "end": {
                    "month": 10,
                    "day": null,
                    "year": 2016
                }
            },
            "profile_positions": [
                {
                    "location": "Bengaluru Area, India",
                    "date": {
                        "start": {
                            "month": 4,
                            "day": null,
                            "year": 2016
                        },
                        "end": {
                            "month": 10,
                            "day": null,
                            "year": 2016
                        }
                    },
                    "company": "Royal Cyber Inc.",
                    "description": "\u2022Planned, designed and implemented diverse business intelligence solutions. \n\u2022Researched, designed and implemented scalable applications for information\nidentification, extraction, analysis, retrieval and indexing.\n\u2022Integrated BI assets into customer relationship management (CRM) tasks, improving service personnel's available intelligence.\n\u2022Drafted strategic business intelligence road-map, complete with data governance policies and tactical information safeguards.\n\u2022Involved in creation/review of functional requirement specifications and supporting documents for business systems, experience in database design process and data modeling process.\n\u2022Designed customized data collection models for specific visualization tasks.\n\u2022Developed intelligence-sharing dashboards, providing company-wide access to collected data.\n\u2022Monitored and optimized SQL server performance.\n\u2022Used Control Flow Tasks like For Loop Container, For Each Loop Container, Sequential Container, Execute SQL Task, Email Task and Data Flow Task.\n\u2022Involved in reports customization using SSRS tools and some part of migration from\nCrystal Reports to SSRS.\n\u2022Interfaced with cross-functional team of business analysts, developers and technical support professionals to determine comprehensive list of requirement specifications\nfor new applications.",
                    "title": "Business Intelligence Developer",
                    "employment_type": "Full-time"
                }
            ]
        },
        {
            "company": {
                "id": 2722733,
                "name": "SAUDI SERVICES CO LTD",
                "logo": "https://media.licdn.com/dms/image/C510BAQF-cXqE0XYiPg/company-logo_400_400/0/1519879689740?e=1703721600&v=beta&t=yZfIcR-TlXyTKwdmN1gYVeFJN_UBqRc9W4slewHNIlo",
                "url": "https://www.linkedin.com/company/saudi-services-co-ltd/",
                "employees": {
                    "start": 1001,
                    "end": 5000
                }
            },
            "date": {
                "start": {
                    "month": 1,
                    "day": null,
                    "year": 2013
                },
                "end": {
                    "month": 1,
                    "day": null,
                    "year": 2015
                }
            },
            "profile_positions": [
                {
                    "location": "Riyadh",
                    "date": {
                        "start": {
                            "month": 1,
                            "day": null,
                            "year": 2013
                        },
                        "end": {
                            "month": 1,
                            "day": null,
                            "year": 2015
                        }
                    },
                    "company": "SAUDI SERVICES CO LTD",
                    "description": "Technical Aspects:\n\uf076\tPrepared SAP Business One 8.82 implementation, installation in server as well as client machines.\n\uf076\tPrepared the installation of Patch Level [PL] upgrade with SAP B1.\n\uf076\tInvolved in configuring the SAP B1 user rights according to the desired authentication & authorization.\n\uf076\tRegular SAP B1 License update in server and configured user level license allocation.\n\uf076\tInstalling, Registering & Configuring Payroll build in server as well as client machines.\n\uf076\tDealing with client fresh requirements and Coordinating with technical consultants.\n\uf076\tInstalled & Implemented Crystal Reports 2008 & Microsoft Business Intelligence 2012 reporting tools for the preparation of various consolidated MIS reports for Payroll, Finance & HR modules as per the requirements from the end-user and uploaded into SAP B1. \n\uf076\tWorked up to some extent on Database Designing, creating Stored Procedures, database Triggers, end-user support and maintenance work.\n\uf076\tCreated user defined tables [UDT] and user defined fields [UDF] in SAP B1 as per the need by end user.\n\uf076\tWorked on Data Transfer Workbench [DTW] for uploading external data into SAP B1.\n\uf076\tWorked on Data Loader [DL] for uploading various General Ledger [GL] related entries into SAP B1 Journal Entries.\n\uf076\tInvolved in creating SSIS packages to migrate data from various sources through ETL method using Sql Server Integration Services.\n\uf076\tPrepared Dataflow, Workflow with reference to the data extraction from various sources to its respective destination database through Business Objects Data Services interface. \nFunctional Aspects:\n\uf076\tPrepared various SQL alert queries for SAP B1 alert prompt as per end user demand.\n\uf076\tCreation of Customized SAP Query Report.\n\uf076\tInvolved in preparing Purchase Quotation, Purchase Order, Good Receipt Pos, A/P Invoice followed by the Outgoing Payments.\n\uf076\tPrepared frequent Journal entries for the respective transactions and involved in preparing reports for both Projects & Cost Centers.",
                    "title": "SAP B1 Consultant",
                    "employment_type": "Full-time"
                }
            ]
        },
        {
            "company": {
                "id": 214814,
                "name": "Glodyne Technoserve Ltd",
                "logo": "https://media.licdn.com/dms/image/C4D0BAQEsyTDYiJH-cQ/company-logo_400_400/0/1519922082890?e=1703721600&v=beta&t=C8UK3rpH928N78NirZbO60yfm8aSxRuuKOcUcWL_t28",
                "url": "https://www.linkedin.com/company/glodyne-technoserve-ltd/",
                "employees": {
                    "start": 1001,
                    "end": 5000
                }
            },
            "date": {
                "start": {
                    "month": 7,
                    "day": null,
                    "year": 2009
                },
                "end": {
                    "month": 12,
                    "day": null,
                    "year": 2012
                }
            },
            "profile_positions": [
                {
                    "location": "Mumbai Area, India",
                    "date": {
                        "start": {
                            "month": 7,
                            "day": null,
                            "year": 2009
                        },
                        "end": {
                            "month": 12,
                            "day": null,
                            "year": 2012
                        }
                    },
                    "company": "Glodyne Technoserve Ltd",
                    "description": "\u2022Designed and implemented complex SSIS package to migrate data from multiple data sources.\n\u2022Created Stored procedure, Views, Cursors and functions to support application.\n\u2022Extensively worked on creating SSIS packages and have used For each Loop containers, Sequence Container for developing processes and loaded data using different transformations such as Derived Columns, Condition Split, Aggregate, Merge Join and Union all.\n\u2022Designed SSIS packages to extract data from different sources like SQL server 2012, MS Excel, Flat Files, transform and then load into Dimension and Fact tables in Data Warehouse using SSIS.\n\u2022Extensively created SSRS reports (Executive Summary report for Annual and Quarterly) and Configured Report Server on all the environments. Also automate deployment for SSRS reports for all the environments.\n\u2022Responsible for working with co-developers in designing packages in SSIS/ETL.\n\u2022Create indexes on the database tables and generate trace event to improve the query performance and optimize data access.\n\u2022Involved in creating T-SQL objects like tables, stored procedures, indexes, user defined functions, common table expression (CTE), Temp table, etc.\n\u2022Configured SQL jobs and maintenance plans to ensure database stability and integrity.\n\u2022Reviewed, analyzed and implemented necessary changes in appropriate areas to enhance and improve existing systems.\n\u2022Provided support by troubleshooting and solving the issues.",
                    "title": "Sr. Software Engineer",
                    "employment_type": null
                }
            ]
        }
    ],
    "volunteer_experiences": [],
    "skills": [
        "Aviation",
        "Data Transformation",
        "Data Ingestion",
        "Azure Functions",
        "Snowflake",
        "Amazon Redshift",
        "Azure Synapse",
        "Microsoft SQL Server",
        "Business Intelligence",
        "Extract, Transform, Load (ETL)",
        "Business Intelligence (BI)",
        "Financial Reporting",
        "Data Warehousing",
        "Data Visualization",
        "Data Modeling",
        "Data Integration",
        "Data Analysis",
        "Master Data Management",
        "Agile Methodologies",
        "Data Migration"
    ],
    "network_info": null,
    "related_profiles": null,
    "contact_info": null
}