{
    "profile_id": "prajakta-takate",
    "first_name": "Prajakta",
    "last_name": "Takate",
    "sub_title": "Data Engineer at Capgemini",
    "profile_picture": "https://media.licdn.com/dms/image/D4E03AQGtRnmI6NVRXw/profile-displayphoto-shrink_800_800/0/1663434234510?e=1701302400&v=beta&t=FfRoRdy0NEOBN1B33RdE05FqNXI2cLLCHq-_74UQqeM",
    "background_image": "https://media.licdn.com/dms/image/C4E16AQHDIT7ujB5GPA/profile-displaybackgroundimage-shrink_350_1400/0/1663435154591?e=1701302400&v=beta&t=kFNZiez0uLkj_iBWXzV8R_HY0hJOAbwVtTOgCVw0ySU",
    "profile_type": "personal",
    "entity_urn": "ACoAAByQuUQB6raRxTmHGz10X4pCVpuEMuLhQ24",
    "object_urn": 479246660,
    "birth_date": null,
    "summary": "Big Data Engineer, Passionate and experienced in designing and executing solutions for complex business problems involving large scale data warehousing, data lakes, real-time analytics, and reporting solutions to increase efficiency, accuracy, and utility of internal data processing. \n\nTechnical skills :\n\u2022\tDWH/RDBMS: Teradata, Oracle, MySQL.\n\u2022\tData processing frameworks: Hadoop, HDFS, Hive, Sqoop, Spark, Kafka.\n\u2022\tETL tools: Informatica, SSIS, Attunity replicate.\n\u2022\tData Visualization: Tableau, Power BI\n\u2022\tProgramming Language: Python, Shell scripting\n\u2022\tOrchestration tool: Control-M, Oozie, Airflow.\n\u2022\tCloud infrastructures: Amazon AWS.\n\u2022\tCI/CD: Azure DevOps\n\n\nHolding HIGHLY SKILLED MIGRANT VISA Netherlands",
    "location": {
        "country": "Netherlands",
        "short": "Zaandam, North Holland",
        "city": "Zaandam",
        "state": "North Holland",
        "default": "Zaandam, North Holland, Netherlands"
    },
    "premium": false,
    "influencer": false,
    "treasury_media": [],
    "languages": {
        "primary_locale": {
            "country": "US",
            "language": "en"
        },
        "supported_locales": [
            {
                "country": "US",
                "language": "en"
            }
        ],
        "profile_languages": [
            {
                "name": "English",
                "proficiency": null
            },
            {
                "name": "Hindi",
                "proficiency": null
            },
            {
                "name": "Marathi",
                "proficiency": null
            }
        ]
    },
    "industry": "Information Technology & Services",
    "education": [
        {
            "date": {
                "start": {
                    "month": null,
                    "day": null,
                    "year": 2018
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": 2019
                }
            },
            "school": {
                "name": "National College of Ireland",
                "logo": "https://media.licdn.com/dms/image/C560BAQGvdEr-87aniQ/company-logo_400_400/0/1519856770148?e=1703721600&v=beta&t=O1BezbMBhUs_HpZoPdEragBWtbBxFWFL4IbWhH4lcvY",
                "url": "https://www.linkedin.com/school/national-college-of-ireland/"
            },
            "degree_name": "Master of Science",
            "field_of_study": "Data analytics ",
            "grade": null
        },
        {
            "date": {
                "start": {
                    "month": null,
                    "day": null,
                    "year": 2012
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": 2015
                }
            },
            "school": {
                "name": "Maharashtra Institute of Technology",
                "logo": "https://media.licdn.com/dms/image/C4E0BAQFGZtKuW-zcig/company-logo_400_400/0/1519908529964?e=1703721600&v=beta&t=xk6mJdlFWsEuRmep-PovvqsQBEwRwJgeUlgHsYpCEVs",
                "url": "https://www.linkedin.com/school/maharashtra-institute-of-technology/"
            },
            "degree_name": "Bachelor of Engineering (B.E.)",
            "field_of_study": "Information Technology",
            "grade": "Distinction"
        },
        {
            "date": {
                "start": {
                    "month": null,
                    "day": null,
                    "year": 2009
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": 2012
                }
            },
            "school": {
                "name": "Government Polytechnic ahmednagar, India",
                "logo": null,
                "url": null
            },
            "degree_name": null,
            "field_of_study": "Computer Technology",
            "grade": "Distinction"
        }
    ],
    "patents": [],
    "awards": [
        {
            "title": "Employee of the Quarter",
            "description": "Delivery Excellence",
            "issuer": null,
            "date": {
                "month": 1,
                "day": null,
                "year": 2018
            }
        }
    ],
    "certifications": [
        {
            "name": "Associate Cloud Engineer",
            "date": {
                "start": {
                    "month": 2,
                    "day": null,
                    "year": 2021
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "authority": "Google Cloud",
            "url": "https://www.credential.net/b0a28286-f55d-4667-8c3a-d205009a44fa?key",
            "license_number": "28400745",
            "display_source": "credential.net",
            "company": {
                "id": null,
                "name": "Google",
                "logo": "https://media.licdn.com/dms/image/C4D0BAQHiNSL4Or29cg/company-logo_400_400/0/1519856215226?e=1703721600&v=beta&t=45pPRW58DELKQ71b8pS1RIvn6yxBngEZqmTF1VwyxzQ",
                "url": null
            }
        },
        {
            "name": "Microsoft Certified: Azure Fundamentals",
            "date": {
                "start": {
                    "month": 9,
                    "day": null,
                    "year": 2020
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "authority": "Microsoft",
            "url": "https://www.youracclaim.com/badges/8035f394-b65f-4feb-a818-6336b26d0856?source=linked_in_profile",
            "license_number": null,
            "display_source": "youracclaim.com",
            "company": {
                "id": null,
                "name": "Microsoft",
                "logo": "https://media.licdn.com/dms/image/C560BAQE88xCsONDULQ/company-logo_400_400/0/1618231291419?e=1703721600&v=beta&t=xic8lPBHmNYz9qHIoiuq_itbJ4T3xDqNu9Bb5EuYkZ0",
                "url": null
            }
        },
        {
            "name": "Teradata 14 SQL certification ",
            "date": {
                "start": {
                    "month": 11,
                    "day": null,
                    "year": 2017
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "authority": "Teradata",
            "url": "https://www.youracclaim.com/badges/ca99fbaa-a635-487d-ae1a-af03835de79b/linked_in_profile",
            "license_number": null,
            "display_source": "youracclaim.com",
            "company": {
                "id": null,
                "name": "Teradata",
                "logo": "https://media.licdn.com/dms/image/C4E0BAQGrLEbqJZRT-w/company-logo_400_400/0/1538982145946?e=1703721600&v=beta&t=JHExVHkz1LEAXcqLcqSaWtohx1MLIJyFnebbvRj9QIY",
                "url": null
            }
        },
        {
            "name": "Teradata 14 Certified Professional",
            "date": {
                "start": {
                    "month": 11,
                    "day": null,
                    "year": 2016
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "authority": "Teradata",
            "url": "https://www.youracclaim.com/badges/936322da-00c5-4c07-9c08-1f437831538c/linked_in_profile",
            "license_number": null,
            "display_source": "youracclaim.com",
            "company": {
                "id": null,
                "name": "Teradata",
                "logo": "https://media.licdn.com/dms/image/C4E0BAQGrLEbqJZRT-w/company-logo_400_400/0/1538982145946?e=1703721600&v=beta&t=JHExVHkz1LEAXcqLcqSaWtohx1MLIJyFnebbvRj9QIY",
                "url": null
            }
        },
        {
            "name": "IBM Big Data - Programming",
            "date": {
                "start": {
                    "month": 2,
                    "day": null,
                    "year": 2016
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "authority": "IBM",
            "url": null,
            "license_number": null,
            "display_source": null,
            "company": {
                "id": null,
                "name": "IBM",
                "logo": "https://media.licdn.com/dms/image/D560BAQGiz5ecgpCtkA/company-logo_400_400/0/1688684715427?e=1703721600&v=beta&t=eAMK4ZqZ9jAX6bPbX5LjyyMurxtQnubuQSv7kNBKpjI",
                "url": null
            }
        },
        {
            "name": "IBM Big Data Foundations ",
            "date": {
                "start": {
                    "month": 2,
                    "day": null,
                    "year": 2016
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "authority": "IBM",
            "url": null,
            "license_number": null,
            "display_source": null,
            "company": {
                "id": null,
                "name": "IBM",
                "logo": "https://media.licdn.com/dms/image/D560BAQGiz5ecgpCtkA/company-logo_400_400/0/1688684715427?e=1703721600&v=beta&t=eAMK4ZqZ9jAX6bPbX5LjyyMurxtQnubuQSv7kNBKpjI",
                "url": null
            }
        },
        {
            "name": "Oracle Database 11g: SQL Fundamentals-I  1Z0-051",
            "date": {
                "start": {
                    "month": null,
                    "day": null,
                    "year": null
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "authority": "Oracle",
            "url": null,
            "license_number": null,
            "display_source": null,
            "company": {
                "id": null,
                "name": "Oracle",
                "logo": "https://media.licdn.com/dms/image/D4E0BAQHYCgYovUuPtQ/company-logo_400_400/0/1665755678671?e=1703721600&v=beta&t=Dm76HdWfxIWnpbvHLebFl3pVU3k77A1u2lhJxvxe8s4",
                "url": null
            }
        }
    ],
    "organizations": [],
    "projects": [
        {
            "title": "Performance Analysis of MongoDB and Hbase Using YCSB",
            "date": {
                "start": {
                    "month": 11,
                    "day": null,
                    "year": 2018
                },
                "end": {
                    "month": 11,
                    "day": null,
                    "year": 2018
                }
            },
            "description": "Key skills used : Hbase, MongoDB, YCSB, openstack , Power BI, Testharnes using shell script.\n\n\u2022\tIn this paper, I performed comparative performance analysis of two popular and widely used database models MongoDB and Hbase, using the YCSB tool which is a framework developed by yahoo for testing the performance of databases. \n\u2022\tI compared both databases under different workloads and different operations to study performance of these databases on various configurations. \n\u2022\tThis study helped me to understand the actual end to end configuration of Hadoop system on distributed environment and infrastructure. ",
            "contributors": [
                {
                    "type": "standardizedContributor",
                    "first_name": "Prajakta",
                    "last_name": "Takate",
                    "name": null,
                    "headline": "Data Engineer at Capgemini"
                }
            ]
        },
        {
            "title": "Automatic Fake News Detection using Natural Language Processing and Machine Learning",
            "date": {
                "start": {
                    "month": 3,
                    "day": null,
                    "year": 2019
                },
                "end": {
                    "month": 5,
                    "day": null,
                    "year": 2019
                }
            },
            "description": "Key skills used: Python, NLTK, Scikit learn,  Machine learning.\n\u2022\tUsed Data preprocessing techniques, feature extraction techniques and machine learning classifiers using python nltk and scikit learn.\n\u2022\tWe compare and investigate the different feature extraction techniques and tested the dataset on different machine learning models to detect fake news.\n",
            "contributors": [
                {
                    "type": "standardizedContributor",
                    "first_name": "Prajakta",
                    "last_name": "Takate",
                    "name": null,
                    "headline": "Data Engineer at Capgemini"
                }
            ]
        },
        {
            "title": "Big Data Processing with Hadoop MapReduce, Hive and Spark Using Adult Census.",
            "date": {
                "start": {
                    "month": 4,
                    "day": null,
                    "year": 2019
                },
                "end": {
                    "month": 5,
                    "day": null,
                    "year": 2019
                }
            },
            "description": "Key skills used:  Hadoop, MapReduce, Hive, Scala, Spark, Sqoop, MySQL, MongoDB, design patterns, Unix scripting, Tableau.\n\u2022\tThis project focuses on architectural and functional level comparison of Hadoop MapReduce, Hive and Spark programming models using adult dataset containing census information.\n\u2022\tThe insights of this data also analyzed while processing the data using these tools.\n\u2022\tMySQL is used for staging purpose and processed outputs have  been stored  in MongoDB  database.\n\u2022\tEnd to end automation process has been added using shell scripting.\n\u2022\tVisualizations   have been computed  using Tableau for  better understanding  of answered.  queries.\n",
            "contributors": [
                {
                    "type": "standardizedContributor",
                    "first_name": "Prajakta",
                    "last_name": "Takate",
                    "name": null,
                    "headline": "Data Engineer at Capgemini"
                }
            ]
        },
        {
            "title": "Airbnb Market Analysis",
            "date": {
                "start": {
                    "month": 10,
                    "day": null,
                    "year": 2018
                },
                "end": {
                    "month": 11,
                    "day": null,
                    "year": 2018
                }
            },
            "description": "Key skills used: R, SSIS, SSAS, SQL Server, Tableau.\n\u2022\tR tool has been used for data extraction, data deployment and cleaning performed on SQL server using SSIS.  Also fetched twitter data using R and performed sentiment analysis.\n\u2022\tEnd to end ETL automation using structured and unstructured data from different sources.\n\u2022\tLearnt Cube designing and implementing data warehouse using Kimball\u2019s bottom up approach.\n\u2022\tTableau is used for critical analysis to show different outcomes of business queries.\n",
            "contributors": [
                {
                    "type": "standardizedContributor",
                    "first_name": "Prajakta",
                    "last_name": "Takate",
                    "name": null,
                    "headline": "Data Engineer at Capgemini"
                }
            ]
        }
    ],
    "publications": [],
    "courses": [],
    "test_scores": [],
    "position_groups": [
        {
            "company": {
                "id": 157240,
                "name": "Capgemini",
                "logo": "https://media.licdn.com/dms/image/D560BAQF_q1awsuPNAg/company-logo_400_400/0/1688232761552?e=1703721600&v=beta&t=qvh3IQNMnfr_K0evOCNqFalngzJKSchvQKll9Gryikc",
                "url": "https://www.linkedin.com/company/capgemini/",
                "employees": {
                    "start": 10001,
                    "end": null
                }
            },
            "date": {
                "start": {
                    "month": 12,
                    "day": null,
                    "year": 2020
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "profile_positions": [
                {
                    "location": "Netherlands",
                    "date": {
                        "start": {
                            "month": 12,
                            "day": null,
                            "year": 2020
                        },
                        "end": {
                            "month": null,
                            "day": null,
                            "year": null
                        }
                    },
                    "company": "Capgemini",
                    "description": null,
                    "title": "Data Engineer",
                    "employment_type": "Full-time"
                }
            ]
        },
        {
            "company": {
                "id": 10042,
                "name": "HEMA",
                "logo": "https://media.licdn.com/dms/image/C560BAQFpIWP40AlVlA/company-logo_400_400/0/1562753448219?e=1703721600&v=beta&t=-2FWHUlWfRQAQW5F-HotbQb-eIAmiA-QuzaHmlN5L_U",
                "url": "https://www.linkedin.com/company/hema/",
                "employees": {
                    "start": 10001,
                    "end": null
                }
            },
            "date": {
                "start": {
                    "month": 8,
                    "day": null,
                    "year": 2021
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "profile_positions": [
                {
                    "location": "Amsterdam, North Holland, Netherlands",
                    "date": {
                        "start": {
                            "month": 8,
                            "day": null,
                            "year": 2021
                        },
                        "end": {
                            "month": null,
                            "day": null,
                            "year": null
                        }
                    },
                    "company": "HEMA",
                    "description": "\u2022\tDeveloped data ingestion pipeline using Kafka and Python.\n\u2022\tBuilt ETL pipelines using Apache Spark & Delta Lake to process structured and semi-structured data \n        from different systems like SAP, Teradata, POS.\n\u2022\tImplemented Airflow DAGs to orchestrate data ingestion pipelines and ETLs. \n\u2022\tBuilt Table/views schemas on consumption layer in Redshift for data analysis and reporting in PowerBI.",
                    "title": "Data Engineer",
                    "employment_type": "Contract"
                }
            ]
        },
        {
            "company": {
                "id": 11149,
                "name": "AXA Partners",
                "logo": "https://media.licdn.com/dms/image/C4E0BAQHvJJio0nB9Mw/company-logo_400_400/0/1592920811699?e=1703721600&v=beta&t=dmKswy6vCSyVxbZniyR-sriZIZPuEo99s22dqbY84e4",
                "url": "https://www.linkedin.com/company/axa-partners/",
                "employees": {
                    "start": 5001,
                    "end": 10000
                }
            },
            "date": {
                "start": {
                    "month": 9,
                    "day": null,
                    "year": 2019
                },
                "end": {
                    "month": 4,
                    "day": null,
                    "year": 2020
                }
            },
            "profile_positions": [
                {
                    "location": "Ireland",
                    "date": {
                        "start": {
                            "month": 9,
                            "day": null,
                            "year": 2019
                        },
                        "end": {
                            "month": 4,
                            "day": null,
                            "year": 2020
                        }
                    },
                    "company": "AXA Partners",
                    "description": "\u2022\tWorked on data pipeline for massive data movement using Attunity replicate server and Hql. \n\u2022\tDeveloped and deployed Oozie workflows for data mart creation and report generation.\n\u2022\tAnalyzed the data using PySpark through Jupyter notebooks.\n\u2022\tExperience on Git and Git bash for version tracking and code management.",
                    "title": "Big Data Engineer",
                    "employment_type": "Contract"
                }
            ]
        },
        {
            "company": {
                "id": 1466,
                "name": "Teradata",
                "logo": "https://media.licdn.com/dms/image/C4E0BAQGrLEbqJZRT-w/company-logo_400_400/0/1538982145946?e=1703721600&v=beta&t=JHExVHkz1LEAXcqLcqSaWtohx1MLIJyFnebbvRj9QIY",
                "url": "https://www.linkedin.com/company/teradata/",
                "employees": {
                    "start": 10001,
                    "end": null
                }
            },
            "date": {
                "start": {
                    "month": 5,
                    "day": null,
                    "year": 2017
                },
                "end": {
                    "month": 8,
                    "day": null,
                    "year": 2018
                }
            },
            "profile_positions": [
                {
                    "location": "Pune, Maharashtra, India",
                    "date": {
                        "start": {
                            "month": 5,
                            "day": null,
                            "year": 2017
                        },
                        "end": {
                            "month": 8,
                            "day": null,
                            "year": 2018
                        }
                    },
                    "company": "Teradata",
                    "description": "\u2022\tDeveloped ETL Applications with informatica and Teradata. Formulated ETL process to handle massive data files having miscellaneous structures simultaneously on daily basis.\n\u2022\tContributed to deliver data migration plans, production handover documentation, database designs, information models (logical, physical, dimensional, etc.) and data warehouses.\n\u2022\tHas extensive work experience on complex queries in Teradata",
                    "title": "ETL Developer",
                    "employment_type": "Full-time"
                }
            ]
        },
        {
            "company": {
                "id": 1009,
                "name": "IBM",
                "logo": "https://media.licdn.com/dms/image/D560BAQGiz5ecgpCtkA/company-logo_400_400/0/1688684715427?e=1703721600&v=beta&t=eAMK4ZqZ9jAX6bPbX5LjyyMurxtQnubuQSv7kNBKpjI",
                "url": "https://www.linkedin.com/company/ibm/",
                "employees": {
                    "start": 10001,
                    "end": null
                }
            },
            "date": {
                "start": {
                    "month": 9,
                    "day": null,
                    "year": 2015
                },
                "end": {
                    "month": 4,
                    "day": null,
                    "year": 2017
                }
            },
            "profile_positions": [
                {
                    "location": "Mindspace, hyderabad",
                    "date": {
                        "start": {
                            "month": 9,
                            "day": null,
                            "year": 2015
                        },
                        "end": {
                            "month": 4,
                            "day": null,
                            "year": 2017
                        }
                    },
                    "company": "IBM",
                    "description": "\u2022\tWorked on Source data validation, integration and modelling, Process automation (Cascade UNIX scripts), FSLDM and Hadoop environment\n\u2022\tWorked on Data Lake Project based on the Hadoop Distributed File System (HDFS). \n\u2022\tWorked with Sqoop to ingest & retrieve data from various RDBMS like Oracle & MySQL to HDFS.\n\u2022\tConstructed ETLs to capture productivity and data quality checks which migrates the processed data from HDFS to Teradata.\n\u2022\tTracked and managed defects along with analyzing data and provided reports to generate visually impactful dashboards in Excel and Tableau.",
                    "title": "Associate Software Engineer",
                    "employment_type": "Full-time"
                }
            ]
        }
    ],
    "volunteer_experiences": [
        {
            "date": {
                "start": {
                    "month": null,
                    "day": null,
                    "year": null
                },
                "end": {
                    "month": null,
                    "day": null,
                    "year": null
                }
            },
            "role": "Robocon, MIT COE",
            "company": {
                "id": null,
                "name": "MIT COE Pune",
                "logo": null,
                "url": null
            },
            "cause": null,
            "description": null
        }
    ],
    "skills": [
        "Big Data",
        "Data Analysis",
        "Apache Spark",
        "Hadoop",
        "SQL",
        "Informatica",
        "Amazon Web Services (AWS)",
        "Scala",
        "Cognos",
        "Oracle Database",
        "R",
        "IBM SPSS",
        "Apache Flume",
        "Oracle SQL",
        "Tableau",
        "Linux",
        "Teradata SQL",
        "Teradata Data Warehouse",
        "Sqoop",
        "Python (Programming Language)"
    ],
    "network_info": null,
    "related_profiles": null,
    "contact_info": null
}